{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ćwiczenia 6. Walidacja Krzyżowa\n",
    "\n",
    "## PyTorch na następne ćwiczenia.\n",
    "\n",
    "Proszę zainstalować pakiet [PyTorch](https://pytorch.org/) oraz torchvision na kolejne zajęcia. Jeśli używane, mając swoje środowisko aktywne użyć:\n",
    "\n",
    " * GPU: `conda install pytorch torchvision cudatoolkit=9.0 -c pytorch`\n",
    " * tylko CPU: `conda install pytorch torchvision cpuonly  -c pytorch`\n",
    "\n",
    "## Klasyfikacja\n",
    "\n",
    "Dzisiaj na zajęciach zajmiemy się problemem klasyfikacji. Podobnie do regresji liniowej jest to przykład uczenia nadzorowanego, ale zamiast przewidywać konkretną liczbę dla danej obserwacji, przewidujemy jego przynajeżność do jednej z *k* klas. Na tych zajęciach będziemy rozważać klasyfikacje binarną, czyli uczyć modele odpowiadające funkcji:\n",
    "\n",
    "$$ f(x) = y, \\quad y \\in \\{0,1\\} $$\n",
    "\n",
    "Poniżej ładowane są dane, do razu już podzielone na dwie części."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import get_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.1 (0.5 pkt.)\n",
    "\n",
    "Używając modelu [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) z pakietu sklearn uzyskać 100% dokładność (mierzoną miarą [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))na zbiorze treningowym. Państwa zadanie polega na dobraniu parametru `gamma`, dla ułatwienia proszę nie zmieniać pozostałych domyślnych parametrów. Zalecany przedział parametru `gamma` to wartości z przedziału [0, 1] w skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005994842503189421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n",
    "wp = np.logspace(-10,0,num=10)\n",
    "wp1 = np.linspace(0.00000001,1,num=100000)\n",
    "j = 0\n",
    "for i in wp:\n",
    "    j=i\n",
    "    svm1 = SVC(gamma = i)\n",
    "    svm1.fit(X_train, y_train)\n",
    "    train_acc1 = svm1.score(X_train, y_train)\n",
    "    if train_acc1 == 1:\n",
    "        break\n",
    "        \n",
    "print(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = j\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "train_acc = svm.score(X_train, y_train)\n",
    "\n",
    "assert train_acc == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.2 (0.5 pkt.)\n",
    "Używając tej samej rodziny modeli znajdź tym razem taką wartość `gamma`, która daje najlepszy wynik na zbiorze **testowym**. Powinieneś(-aś) być w stanie osiągnąć wynik co najmniej `0.95` accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.782559402207126e-06\n",
      "0.951048951048951\n",
      "[1.00000000e-10 1.29154967e-09 1.66810054e-08 2.15443469e-07\n",
      " 2.78255940e-06 3.59381366e-05 4.64158883e-04 5.99484250e-03\n",
      " 7.74263683e-02 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n",
    "wp2 = np.logspace(-10,0,num=10)\n",
    "wp3 = np.linspace(0.00000001,1,num=10000)\n",
    "z = 0\n",
    "for i in wp2:\n",
    "    z=i\n",
    "    svm2 = SVC(gamma = i)\n",
    "    svm2.fit(X_train, y_train)\n",
    "    train_acc2 = svm2.score(X_test, y_test)\n",
    "    if train_acc2 >= 0.95:\n",
    "        break\n",
    "\n",
    "print(z)\n",
    "print(train_acc2)\n",
    "print(wp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = z # ???\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "assert test_acc >= 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "**W poprzednim zadaniu zakładaliśmy, że podział na zbiór trenujący/testujący jest nam podany z góry, ale co jeśli go nie mamy?**\n",
    "\n",
    "Możemy oczywiście sami arbitralnie wybrać część datasetu i uznać ją za nasz zbiór testowy, ale to mogą się z tym wiązać dodatkowe problemy: co jeśli wybrany przez nas fragment jest akurat różny od reszty datasetu, lub odwrotnie?\n",
    "\n",
    "**Rozwiązanie:** Walidacja Krzyżowa.\n",
    "\n",
    "1. Podziel dataset na zadaną przez parametr `k` liczbę (prawie) równych grup.\n",
    "2. Dla każdego podziału, zwróć jedną z tych części jako zbiór testowy, a sumę reszty jako zbiór treningowy.\n",
    "3. Po nauczeniu łącznie `k` modeli, uśrednij ich wyniki na zbiorach testowych i zwróć jako ostateczny wynik.\n",
    "\n",
    "## Zadanie 2. (2 pkt.)\n",
    "\n",
    "Państwa zadaniem jest zaimplementowanie walidacji krzyżowej, czyli funkcji, która dla podanego datasetu w postaci macierzy danych `X` i wektora etykiet `y` zwróci listę `k` krotek: \n",
    "  \n",
    "  `(treningowe_dane, treningowe_etykiety, testowe_dane, testowe_etykiety)`\n",
    "  \n",
    "podziałów dokonanych przez walidację krzyżową. Następnie należy użyć modelu z poprzedniego zadania dla policzenia dokładności na zbiorze testowym dla walidacji krzyżowej.\n",
    "\n",
    "Proszę **nie** korzystać z gotowych rozwiązań dostępnych w pakiecie sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def cross_validation(X: np.ndarray, y: np.ndarray, k: int) -> List[Tuple[np.ndarray, np.ndarray, \n",
    "                                                                         np.ndarray, np.ndarray]]:\n",
    "    # your code here\n",
    "    X_split = list(split(X,k))\n",
    "    y_split = list(split(y,k))\n",
    "    treningowe_dane = []\n",
    "    treningowe_etykiety = []\n",
    "    testowe_dane = []\n",
    "    testowe_etykiety = []\n",
    "    wynik_koncowy = []\n",
    "    #print(X_split,y_split,X_conc)\n",
    "    for i in range(k):\n",
    "        testowe_dane.clear()\n",
    "        testowe_etykiety.clear()\n",
    "        \n",
    "        X_split_copy = X_split.copy()\n",
    "        y_split_copy = y_split.copy()\n",
    "        testowe_dane.append(X_split_copy.pop(i))\n",
    "        testowe_etykiety.append(y_split_copy.pop(i))\n",
    "        \n",
    "        treningowe_dane = np.concatenate(X_split_copy)\n",
    "        treningowe_etykiety = np.concatenate(y_split_copy)\n",
    "        \n",
    "        tsd = np.asarray(testowe_dane[0])\n",
    "        tse = np.asarray(testowe_etykiety[0])\n",
    "        trd = np.asarray(treningowe_dane)\n",
    "        tre = np.asarray(treningowe_etykiety)\n",
    "        Tuple = (trd,tre,tsd,tse)\n",
    "        wynik_koncowy.append(Tuple)\n",
    "    \n",
    "    return wynik_koncowy\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import test_cv\n",
    "\n",
    "test_cv(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8489830771619313\n"
     ]
    }
   ],
   "source": [
    "X, y = get_data(split=False)\n",
    "# test\n",
    "\n",
    "\n",
    "\n",
    "#svm.fit(X_train, y_train)\n",
    "#test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "#assert test_acc >= 0.95\n",
    "cv_accuracy = 0\n",
    "k =5\n",
    "svm2 = SVC(gamma = 0.00000001)\n",
    "wynik = cross_validation(X,y,k)\n",
    "for i in range(k):\n",
    "    svm2.fit(wynik[i][0], wynik[i][1])\n",
    "    train_acc2 = svm2.score(wynik[i][2], wynik[i][3])\n",
    "    #print(train_acc2)\n",
    "    cv_accuracy += train_acc2\n",
    "print(cv_accuracy/k) #dokładność vc na zbiorze testowym dla stałego parametru gamma = 0.00000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (1 pkt.)\n",
    "\n",
    "Mając już lepszą metodę walidacji naszego rozwiązania Państwa zadaniem jest znalezienia najlepszego zestawu hiperparametrów dla modelu z poprzednich zadań, lecz tym razem będziemy szukać również parametru `C`. Parametru C zaleca się szukać w przedziale $(0, + \\infty)$ również w skali logarytmicznej.\n",
    "\n",
    "W zadaniu należy oczywiście skorzystać z zaimplementowanej przez Państwa walidacji krzyżowej. Ponieważ dla dwóch parametrów `C` oraz `gamma` możliwych kombinacji do przetestowania robi są dość sporo dla przetestowania dużych zakresów zalecane są również inne metody przeszukiwania, takie jak:\n",
    "\n",
    "* przeszukiwanie po kolei z jednym z parametrów ustalonym na stałą.\n",
    "* przeszukiwanie losowe obu parametrów\n",
    "\n",
    "Oczywiście jeśli zasoby na to pozwalają można szukać tzw. \"grid searchem\".\n",
    "\n",
    "Powinno udać się Państwu wyciągnąć przynajmniej `0.94` accuracy na walidacji krzyżowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9455364073901569\n",
      "2.782559402207126e-06\n",
      "27825.59402207126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "wp2 = np.logspace(-10,0,num=10) #gamma\n",
    "wp3 = np.logspace(0,10,num=10) #C\n",
    "cv_accuracy = 0\n",
    "wynik1 = 0\n",
    "gamma_wynik = 0\n",
    "C_wynik = 0\n",
    "k =5\n",
    "# your code here\n",
    "#print(wp2)\n",
    "#print(wp3)\n",
    "for i in range (10):\n",
    "    cv_accuracy = 0\n",
    "    svm2 = SVC(gamma = wp2[i], C =wp3[i])\n",
    "    wynik = cross_validation(X,y,k)\n",
    "    for j in range(k):\n",
    "        svm2.fit(wynik[j][0], wynik[j][1])\n",
    "        train_acc2 = svm2.score(wynik[j][2], wynik[j][3])\n",
    "        #print(train_acc2)\n",
    "        cv_accuracy += train_acc2\n",
    "    #print(cv_accuracy/k)\n",
    "    if cv_accuracy/k >= 0.94:\n",
    "        wynik1 = cv_accuracy/k\n",
    "        gamma_wynik = wp2[i]\n",
    "        C_wynik = wp3[i]\n",
    "    \n",
    "print(wynik1) # nasze accuracy\n",
    "print(gamma_wynik) # gamma\n",
    "print(C_wynik) # C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4. (3 punkty)\n",
    "\n",
    "Załóżmy, że naszym problemem jest zdecydowanie, która rodzina modeli *SVM* najlepiej radzi sobei z naszym datasetem. Przez rodzinę rozumiemy tutaj modele SVM z różną *funkcją bazwoą* (zwaną często *funkcją jądra*). W pakiecie mamy dostępne kilka możliwości, włącznie z podawaniem swoich własnych, ale w tym zadaniu skupimy się na czterech dostępnych od ręki: `linear`, `poly`, `rbf`, `sigmoid`.\n",
    "\n",
    "Wiemy jak znaleźć najlepszy zestaw parametrów dla danej rodziny modeli, zrobiliśmy to do tej pory dla domyślnej funkcji bazowej czyli `rbf`. Jak jednak mamy \"uczciwie\" porównać wyniki modeli pomiędzy sobą? Do tej pory patrzyliśmy na wyniki modelu dla datasetu testowego i to na podstawie tego wyniku wybieraliśmy najlepsze hiperparametry. Jakie mogą być z tym problemy? Overfitting?\n",
    "\n",
    "Rozwiązanie: jeszcze jedna walidacja krzyżowa!\n",
    "\n",
    "1. Pierwsza walidacja krzyżowa podzieli nam nasz zbiór na treningowy i testowy. Te testowe zbiory będą naszymi ostatecznymi zbiorami testowymi, na których nie będziemy w żaden sposób się uczyć czy szukać hiperparametrów. \n",
    "2. Następnie nasz zbiór treningowy podzielimy ponownie walidacją krzyżową na dwie części: faktyczny treningowy i walidacyjny. Tych dwóch podziałów będziemy używać jak poprzednio do uczenia modelu i testowania hiperparametrów.\n",
    "3. Po znalezieniu najlepszego zestawu hiperparametrów nauczymy ostatecznie nasz model na sumie zbiorów treningowego i walidacyjnego i sprawdzimy jego dokładność na ostatecznym zbiorze testowym.\n",
    "\n",
    "\n",
    "**Uwaga**: parametr `C` używany jest dla każdej możliwej funkcji bazowej. Proszę sprawdzić jakie parametry są używane dla jakich funkcji jądra. \n",
    "**Hint**: parametry, które mogą państwa interesować to oczywiście `kernel`, oraz `C`, `degree`, `gamma`, `coef0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = rbf\n",
      "[0.8771929824561403, 0.956140350877193, 0.9736842105263158, 0.956140350877193, 0.9469026548672567]\n",
      "0.9420121099208197\n"
     ]
    }
   ],
   "source": [
    "#POROWNANIE SIGMOID I RBF\n",
    "from sklearn.svm import SVC\n",
    "import statistics\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "#NESTED CROSS VALIDATION KERNEL = 'rbf'                               (treningowe_dane, treningowe_etykiety, testowe_dane, testowe_etykiety)\n",
    "gamma_wartosci = np.logspace(-10,0,num=10) #gamma\n",
    "C_wartosci = np.logspace(0,10,num=10)#C\n",
    "degree_wartosci = np.linspace(0,9,num = 10)#degree\n",
    "\n",
    "train_acc_list = []\n",
    "lista_koncowa_dcv = []\n",
    "\n",
    "k = 5\n",
    "for j in range(k):\n",
    "    first_cross_validation = cross_validation(X,y,k)\n",
    "    for i in range(k-1):\n",
    "        train_acc_list.clear()\n",
    "        second_cross_validation = cross_validation(first_cross_validation[i][0],first_cross_validation[i][1],k-1)\n",
    "        for w in range(10):\n",
    "            SVM_dcv = SVC(kernel = 'rbf',C = C_wartosci[w],gamma = gamma_wartosci[w],degree = degree_wartosci[w],coef0 = 0 )\n",
    "            SVM_dcv.fit(second_cross_validation[i][0], second_cross_validation[i][1])\n",
    "            train_acc2 = SVM_dcv.score(second_cross_validation[i][2], second_cross_validation[i][3])\n",
    "            train_acc_list.append(train_acc2)\n",
    "        training_error_min_index = train_acc_list.index(max(train_acc_list))\n",
    "        best_gamma = gamma_wartosci[training_error_min_index]\n",
    "        best_C = C_wartosci[training_error_min_index]\n",
    "    SVM_dcv = SVC(kernel = 'rbf',C = best_C,gamma = best_gamma)\n",
    "    SVM_dcv.fit(first_cross_validation[j][0],first_cross_validation[j][1])\n",
    "    lista_koncowa_dcv.append(SVM_dcv.score(first_cross_validation[j][2],first_cross_validation[j][3]))\n",
    "srednia_koncowa = statistics.mean(lista_koncowa_dcv)\n",
    "print('kernel = rbf')\n",
    "print(lista_koncowa_dcv)\n",
    "print(srednia_koncowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = sigmoid\n",
      "[0.6491228070175439, 0.7894736842105263, 0.9035087719298246, 0.9385964912280702, 0.911504424778761]\n",
      "0.8384412358329452\n"
     ]
    }
   ],
   "source": [
    "#NESTED CROSS VALIDATION KERNEL = 'sigmoid'   \n",
    "gamma_wartosci = np.logspace(-10,0,num=10) #gamma\n",
    "C_wartosci = np.logspace(0,10,num=10)#C\n",
    "degree_wartosci = np.linspace(0,9,num = 10)#degree\n",
    "\n",
    "train_acc_list = []\n",
    "lista_koncowa_dcv = []\n",
    "\n",
    "k = 5\n",
    "for j in range(k):\n",
    "    first_cross_validation = cross_validation(X,y,k)\n",
    "    for i in range(k-1):\n",
    "        train_acc_list.clear()\n",
    "        second_cross_validation = cross_validation(first_cross_validation[i][0],first_cross_validation[i][1],k-1)\n",
    "        for w in range(10):\n",
    "            SVM_dcv = SVC(kernel = 'sigmoid',C = C_wartosci[w],gamma = gamma_wartosci[w],degree = degree_wartosci[w],coef0 = 0)\n",
    "            SVM_dcv.fit(second_cross_validation[i][0], second_cross_validation[i][1])\n",
    "            train_acc2 = SVM_dcv.score(second_cross_validation[i][2], second_cross_validation[i][3])\n",
    "            train_acc_list.append(train_acc2)\n",
    "        training_error_min_index = train_acc_list.index(max(train_acc_list))\n",
    "        best_gamma = gamma_wartosci[training_error_min_index]\n",
    "        best_C = C_wartosci[training_error_min_index]\n",
    "        best_degree = degree_wartosci[training_error_min_index]\n",
    "    SVM_dcv = SVC(kernel = 'sigmoid',C = best_C,gamma = best_gamma,degree = best_degree,coef0 = 0)\n",
    "    SVM_dcv.fit(first_cross_validation[j][0],first_cross_validation[j][1])\n",
    "    lista_koncowa_dcv.append(SVM_dcv.score(first_cross_validation[j][2],first_cross_validation[j][3]))\n",
    "srednia_koncowa = statistics.mean(lista_koncowa_dcv)\n",
    "print('kernel = sigmoid')\n",
    "print(lista_koncowa_dcv)\n",
    "print(srednia_koncowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
